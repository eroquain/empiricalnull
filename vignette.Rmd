---
title: "False discovery rate control with unknown null distribution: illustrations on real data sets"
author: "Etienne Roquain and Nicolas Verzelen"
date: "`r Sys.Date()`"
output:
   pdf_document: 
     number_sections: yes
     toc: yes
   rmarkdown::html_vignette:
     number_sections: yes
     toc: yes
bibliography: bibliovignette.bib
vignette: |
---
  
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  warning = FALSE, 
collapse = TRUE,
comment = "#>",
fig.width=8,
fig.height=6
)
```


This vignette illustrates some of the results delineated in @RV2019 for classical case/control data sets. 


```{r install-r-packages, results='hide', message=FALSE}
require("sansSouci.data") || remotes::install_github("pneuvial/sanssouci.data")
```

```{r load-r-packages, results='hide', message=FALSE}
library(sda)
library(multtest)
library(Equalden.HD)
library(locfdr)
library(plot.matrix)
```

Set the seed of the random number generator for numerical reproducibility of the results:
```{r set-seed}
set.seed(20200924)
```

# Theoretical null approach 

In this section, we consider classical case/control real data sets and we show that the theoretical null distribution $\mathcal{N}(0,1)$ can be inadequate to describe the overall behavior of the  test statistics $(Y_i,1\leq i \leq n)$. 

## Standard analysis: the prostate cancer data set 

The @Singh2002 prostate cancer data set provides gene expression measures for two populations : a control group, which corresponds to "healthy" cells, and a case group, which corresponds to tumoral tissues.
Based on this data set, we aim at identifying which genes are differentially expressed between the two groups. 

The data are given under the form of a $d\times n$ matrix $X$, $d=d_0+d_1$, where $d_0$ (resp. $d_1$) denotes the number of replications of the $n$-dimensional measurements for control (resp. case) individuals. The matrix $X$ is derived as follows:

```{r prostate cancer data set}
data(singh2002)
prostate=singh2002
X=prostate$x
#prostate$y
#dim(X)
d=dim(X)[1] 
n=dim(X)[2] 
d0=sum(prostate$y==prostate$y[1]) # control group
d1=d-d0 # case group  
```

Note that the control group is given by the $d_0$ first rows of $X$.

The vector of observed test statistics $Y=(Y_1,\dots,Y_n)$ is then built from $X$ via a standard $t$-test and a suitable Gaussian normalization: 

```{r get test statistics}
getY=function(X,d0,d){
  pvalues=apply(X,2,function(data) 
    t.test(data[1:d0],data[(d0+1):d],var.equal=TRUE,alternative = c("greater"))$p.value)
  Y=-qnorm(pvalues)
}
Y=getY(X,d0,d)
```

Assuming that each line of $X$ follows a two-sample Gaussian model,  the $p$-value corresponding to a gene $i$ such that the "control" group has the same mean than the "case" group has a marginal distributions which is uniform. 
Hence, if we are confident in this Gaussian modeling, the above normalization ensures that the marginal distribution of the corresponding $Y_i$ under the null is $\mathcal{N}(0,1)$. Henceforth, this null distribution is referred as the *theoretical null distribution*.

We display how the theoretical null fits the overall shape of the histogram of the $Y_i$'s: 


```{r fit theoretical null}
par(mfrow=c(1,2))
hist(Y,nclass=70,ylim=c(0,1.6/sqrt(2*pi)),freq=FALSE,main="")
curve(dnorm(x),lwd=2,add=TRUE)
hist(Y,nclass=70,freq=FALSE,add=TRUE)
qqnorm(Y,xlab="",ylab="")
abline(a=0,b=1)
```

We note that the fit is acceptable, so that it seems reasonable to run the standard BH procedure with this theoretical null, as follows.

```{r BH procedure}
BH=function(Y,alpha){
	n=length(Y)
	pvalues=2*(1-pnorm(abs(Y)))
	sortpvalues=sort(pvalues)
	rejet = sortpvalues <= alpha*1:n/n
	threshold=0
	if(sum(rejet)>0) threshold = max(which(rejet))
	rejectedset=which(pvalues<=alpha*threshold/n)
  nbrejections=length(rejectedset)    
	return(nbrejections)
}
```

```{r run BH procedure}
nbrejections=BH(Y,alpha=0.1)
```

Assuming that the BH procedure is well controlling the FDR in that context, it suggests that the `r nbrejections` identified genes contained at most $\alpha=10\%$ of false discoveries (on average).


## Criticism of theoretical null


We apply below the same pipe-line of analyses to the four data sets @Golub99,   @Hed2001, @van2003 and @BGH2010.


```{r fit theoretical null for four data sets}
# Golub et al. (1999) gene expression dataset
data(golub)
X=t(golub)
d=length(golub.cl)
d0=sum(golub.cl==golub.cl[1]) # control
d1=d-d0 # case
Ygolub=getY(X,d0,d)
nbrejectionsgolub=BH(Ygolub,alpha=0.1)
# Hedenfalk et al. (2001) breast cancer dataset
data(Hedenfalk)
X=t(Hedenfalk)
d=dim(X)[1]
d0=7
Yheden=getY(X,d0,d)
nbrejectionsheden=BH(Yheden,alpha=0.1)
# vanâ€™t Wout et al. (2003) HIV data set
data(hivdata)
Ywout=hivdata
nbrejectionshiv=BH(Ywout,alpha=0.1)
# Bourgon et al (2010) acute lymphoblastic leukemia (ALL) data set
data(expr_ALL, package = "sansSouci.data")
X=t(expr_ALL)
X=X[c(which(rownames(X)=="NEG"), which(rownames(X)=="BCR/ABL")),]
d=dim(X)[1]
d0=length(which(rownames(X)=="NEG"))
YBourgon=getY(X,d0,d)
nbrejectionsALL=BH(YBourgon,alpha=0.1)
```

The four fits of the corresponding theoretical nulls are displayed below. 

```{r criticism of theoretical null (histograms)}
par(mfrow=c(2,2))
hist(Ygolub,nclass=70,ylim=c(0,1.6/sqrt(2*pi)),freq=FALSE,main="",xlab="Golub et al. (1999)",ylab="")
curve(dnorm(x),lwd=2,add=TRUE)
hist(Ygolub,nclass=70,freq=FALSE,add=TRUE)
hist(Yheden,nclass=70,ylim=c(0,1.6/sqrt(2*pi)),freq=FALSE,main="",xlab="Hedenfalk et al. (2001)",ylab="")
curve(dnorm(x),lwd=2,add=TRUE)
hist(Yheden,nclass=70,freq=FALSE,add=TRUE)
hist(Ywout,nclass=70,ylim=c(0,1.6/sqrt(2*pi)),freq=FALSE,main="",xlab="van't Wout et al. (2003)",ylab="")
curve(dnorm(x),lwd=2,add=TRUE)
hist(Ywout,nclass=70,freq=FALSE,add=TRUE)
hist(YBourgon,nclass=70,ylim=c(0,1.6/sqrt(2*pi)),freq=FALSE,main="",xlab="Bourgon et al (2010)",ylab="")
curve(dnorm(x),lwd=2,add=TRUE)
hist(YBourgon,nclass=70,freq=FALSE,add=TRUE)
```

```{r criticism of theoretical null (QQplots)}
par(mfrow=c(2,2))
qqnorm(Ygolub,xlab="Golub et al. (1999)",ylab="",main="")
abline(a=0,b=1)
qqnorm(Yheden,xlab="Hedenfalk et al. (2001)",ylab="",main="")
abline(a=0,b=1)
qqnorm(Ywout,xlab="van't Wout et al. (2003)",ylab="",main="")
abline(a=0,b=1)
qqnorm(YBourgon,xlab="Bourgon et al (2010)",ylab="",main="")
abline(a=0,b=1)
```


The four fits are rather poor and it seems that many $Y_i$'s do not follow the theoretical null distribution. This could imply that most alternative hypotheses are true, which would imply that most genes are differentially expressed. Alternatively, this could be due to the fact that the theoretical null is inadequate here and that, under the null (no differential expression of gene $i$), the $Y_i$'s follow a different distribution.  
Unless the statistician has a strong belief that most genes are differentially expressed, 
the theoretical null is inadequate here. In particular, in a sparse situation  where there are only a few alternative, relying on the theoretical null $\mathcal{N}(0,1)$ could be desastrous.

This observation was originally made in by @Efron2008 who also gave some  possible explanations for this phenomenon.  In particular, he hypothetized  that the presence of confounding factors or  strong correlations between the genes: while the (unconditional) marginal distribution of $Y_i$ could be standard normal, the empirical distribution of the sample $(Y_i,1\leq i\leq n)$ would be different. 



# Empirical null approaches

The previous section shows that the theoretical null can be inadequate. In this section, we show that fitting an empirical null distribution to the data can yield to a more meaningful result.


As investigated by @Efron2008, a part of the phenomenon delineated in the above section can be captured by rescaling the null appropriately by some mean $\theta$ and standard deviation $\sigma$. Indeed, the scaling parameters $(\theta,\sigma)$ can be considered as factors disturbing all the measurements simultaneously, that induce some dependencies between the $Y_i$'s when some of these two are random. Namely, if $Y_i=\theta+\sigma\xi_i$ under the null for $\xi_i$ i.i.d. $\mathcal{N}(0,1)$, with $\theta\sim \mathcal{N}(0,1-\sigma^2)$ (and independent), then the null distribution is $\mathcal{N}(0,1)$ *unconditionnally on the scaling* but becomes $\mathcal{N}(\theta,\sigma^2)$ *conditionnally on the scaling*. To this respect, estimating the conditional null could be more meaningful that the unconditional one, and solve partially the gap observed in the previous pictures. In addition, conveniently, the measurements $Y_i$'s are independent conditionnally on the scaling parameters in this case, at least those under the nulls. 

This suggests to consider the Huber model (with fixed mixture) used in @RV2019 where the observations $(Y_i,1\leq i\leq n)$ are assumed to be *independent*, with most of them coming from some unknown null distribution $F_0$, typically some scaled Gaussian, while the remaining ones are let arbitrary. The aim here is to estimate $F_0$ so that the corresponding (plug-in) BH procedure has good performances.


## A new goodness of fit test for the null distribution


First, let us investigate the criticism raised by Efron, by testing whether the null c.d.f. $F_0$ could be equal to the theoretical null c.d.f. $\Phi$, that is, the standard Gaussian tail. To this end, the new goodness of fit test developed in @RV2019 can be used. This test requires the statistician to set a prescribed upper bound  $\overline{\pi}$ on the proportion of true alternatives in the data.

Recall that this test reject the hypothesis $F_0=\Phi$ if            
\begin{align}
\exists k\in \{0,\dots,n\}, \mbox{ such that } \tilde{a}_n(k;\Phi) > \tilde{b}_n(k;\Phi),\label{test}
\end{align}
where 
\begin{align*}
\tilde{a}_n(k;F_0)&=0\vee \frac{\max_{0\leq \ell\leq k}\left\{\ell/n-(1-\overline{\pi})F_0(Y_{(\ell)})\right\}-c_{n,\alpha}}{\overline{\pi}} ;
\\
\tilde{b}_n(k;F_0)&=1\wedge \frac{\min_{k\leq \ell\leq n}\left\{\ell/n-(1-\overline{\pi})F_0(Y_{(\ell+1)})\right\}+c_{n,\alpha}}{\overline{\pi}},
\end{align*}
where $c_{n,\alpha}=\{-(1-\overline{\pi})\log(\alpha/2)/(2n)\}^{1/2}$ and $\alpha$ is the level of the test. 

These quantities and the test can be derived as follows.

```{r goodness of fit for the null distribution}
getcnalpha=function (n,alpha,pibar) sqrt(-(1-pibar)*log(alpha/2)/(2*n))

getankbnkF0=function(alpha,F0,pibar,Y){
  n=length(Y)
  cnalpha=getcnalpha(n,alpha,pibar)
  sortY=sort(Y)
  truca=c(0,sapply(1:n,function(l) l/n-(1-pibar)*F0(sortY[l])))
  ank=pmax(0,(cummax(truca)-cnalpha)/pibar)
  #plot(ank)
  trucb=c(sapply(0:(n-1),function(l) l/n-(1-pibar)*F0(sortY[l+1])),1)
  bnk=pmin(1,(cummin(trucb[(n+1):1])[(n+1):1]+cnalpha)/pibar)
  #plot(bnk)
  return(matrix(c(ank,bnk), n+1,2,byrow=FALSE))
}

acceptF0=function(alpha,F0,pibar,Y){
 n=length(Y)
 res=getankbnkF0(alpha,F0,pibar,Y)
 return(sum(res[,1]<=res[,2])>n)
}

getpvalueF0=function(alpharange,F0, pibar,Y){
  accept=sapply(alpharange, function(alpha) acceptF0(alpha,F0,pibar,Y))
  pvalue=1
  set=which(accept==FALSE)
  if(length(set)>0) pvalue=alpharange[min(set)]
  return(pvalue)
}

alpharange=sort(exp(-seq(0.1,20,1)),decreasing = FALSE)
pibar=0.1 #allows quite dense signal

tab <- data.frame("Data" = c("Golub","Heden", "HIV","ALL"), 
                  "p-value" = c(getpvalueF0(alpharange,pnorm,pibar,Ygolub),
                  getpvalueF0(alpharange,pnorm,pibar,Yheden), getpvalueF0(alpharange,pnorm,pibar,Ywout),
                  getpvalueF0(alpharange,pnorm,pibar,YBourgon)
                  ),check.names = FALSE, row.names = NULL)
knitr::kable(tab)
```

We have set $\bar{\pi}=0.1$ in the example thereby allowing for possibly dense signal. 
The test rejects the null hypothesis $F_0=\Phi$ for all four data sets.


## Gaussian empirical null

Since the theoretical null cannot be used for $F_0$, we should investigate the delicate task of estimating $F_0$ from the data. Following Efron's  argument, we assume that $F_0$ is Gaussian, with some scaling parameters $\theta,\sigma^2$. Hence, the null estimation problem boils down to inferring these scaling parameters. For this, we rely on the classical optimal robust estimators, that is the median  $\widetilde{\theta}$ and the median of absolute deviation $\widetilde{\sigma}$ (MAD) of the sample, respectively.


```{r scaling functions}
getthetatilde=function(Y) quantile(Y,1/2,type=1)
getsigmatilde=function(Y) quantile(abs(Y-getthetatilde(Y)),1/2,type=1)/sqrt(qchisq(1/2,d=1))
```

The empirical null distributions $\mathcal{N}(\widetilde{\theta},\widetilde{\sigma}^2)$ are displayed below for the four  data sets considered above.

```{r empirical null distribution}
plotempfit=function(Y){
  thetatilde=getthetatilde(Y)
  sigmatilde=getsigmatilde(Y)
  hist(Y,nclass=70,ylim=c(0,1.6/sqrt(2*pi)),freq=FALSE,main="") 
curve(dnorm(x),lwd=2,add=TRUE)
curve(dnorm(x,thetatilde,sigmatilde),lwd=2,lty=2,add=TRUE,col="red")
hist(Y,nclass=70,freq=FALSE,add=TRUE)
legend("topright",c("N(0,1)",
        paste("N(",signif(thetatilde,2),",",signif(sigmatilde^2,2),")")),
       lwd=c(2,2),lty=c(1,2),col=c("black","red"),cex=0.8)
return(c(BH(Y,alpha=0.1),BH((Y-thetatilde)/sigmatilde,alpha=0.1)))
}

par(mfrow=c(2,2))
nbrejetgolub=plotempfit(Ygolub)
nbrejetheden=plotempfit(Yheden)
nbrejetWout=plotempfit(Ywout)
nbrejetBourgon=plotempfit(YBourgon)
```


```{r empirical null distribution QQplot}
par(mfrow=c(2,2))
qqnorm(Ygolub,xlab="",ylab="")
abline(a=0,b=1)
qqnorm(Yheden,xlab="",ylab="")
abline(a=0,b=1)
qqnorm(Ywout,xlab="",ylab="")
abline(a=0,b=1)
qqnorm(YBourgon,xlab="",ylab="")
abline(a=0,b=1)
```


## Plug-in BH procedure

The plug-in BH procedure is the Benjamini Hochberg procedure @BH1995  used with empirical Gaussian null distributions. In @RV2019, it has been shown that, if the proportion of true alternatives is small enough in the data, that is, if the sparsity is small enough, this plug-in BH procedure mimicks the oracle-BH procedure. Here, we report the number of rejections of the plug-in BH procedure for the four above data sets.

```{r plug-in BH procedure}
tab <- data.frame("Data" = c("Golub","Heden", "Wout","Bourgon"), 
                  "theoretical BH procedure" = c(nbrejetgolub[1],nbrejetheden[1], nbrejetWout[1],nbrejetBourgon[1]),
                  "plug-in BH procedure" = c(nbrejetgolub[2],nbrejetheden[2], nbrejetWout[2],nbrejetBourgon[2]),check.names = FALSE, row.names = NULL)
knitr::kable(tab)
```

It is apparent that the discovered variables highly depend on the plugged null distribution. For instance, for the data @Golub99, the theoretical BH procedure makes $876$ discoveries, while the empirical BH procedure does not make any discovery. For @van2003, this is the other way around ; the theoretical BH procedure makes only $22$ discoveries, while the empirical BH procedure makes $111$ discoveries. Hence, the theoretical BH procedure could generate a lot of false discoveries (or false non-discoveries).  
This reinforces the interest in suitably estimating the null before applying the BH procedure.


## Label-permuted empirical null

In (multiple) testing, a popular method for estimating the null is to use permutations of the labels. Let us investigate how this compares to the previous method in our context. 

The permutation method consists in switching randomly the labels case/control in the data base to mimick the situation where the individuals are exchangeable accross the sample. Since there are several variables, there are basically two ways to achieve this:

- either we consider a permutation per variable, that is, each column of the matrix $X$ is permuted independently. In that case, the dependence structure accross the variables is lost;

- or the permutations act simultaneously on all the variables, that is, the permutation operation is applied to the whole lines of the matrix $X$. In that case, the dependence structure accross the variables is maintained;

We focus on the second situation which keeps the dependence structure information. We can compute the permuted measurements $X^{(b)}$, $b=1,\dots,B$, obtained by applying $B$ permutations to the lines of $X$. Then, applying each time our function `getY(X,d0,d)`, we obtain a sample $(Y^{(b)}, b=1,\dots,B)$ of variables in $\mathbb{R}^n$. 

```{r function for obtaining the permuted sample}
getpermY=function(X,d0,d,B){
  Yperm=sapply(1:B, function(b)  getY(X[sample(d),],d0,d))
  return(Yperm)
}
```

Doing so, the empirical distribution of each $Y^{(b)}$ can be used to approximate the overall null distribution. Let us apply this for the data set Hedenfalk et al. (2001).

```{r application of permutations for estimating the null}
data(Hedenfalk)
X=t(Hedenfalk)
d=dim(X)[1]
d0=7
B=9
Yperm=getpermY(X,d0,d,B)
thetatilde=getthetatilde(Yheden)
sigmatilde=getsigmatilde(Yheden)

par(mfrow=c(sqrt(B),sqrt(B)))
for (b in 1:B){
  hist(Yheden,nclass=70,ylim=c(0,1.6/sqrt(2*pi)),freq=FALSE,main="") 
hist(Yperm[,b],nclass=70,freq=FALSE,add=TRUE,col="blue",border="blue")
  curve(dnorm(x),lwd=2,add=TRUE)
curve(dnorm(x,thetatilde,sigmatilde),lwd=2,lty=2,add=TRUE,col="red")
hist(Yheden,nclass=70,freq=FALSE,add=TRUE)
legend("topright",c("N(0,1)",
        paste("N(",signif(thetatilde,2),",",signif(sigmatilde^2,2),")"),"Permutation"),
       lwd=c(2,2,2),lty=c(1,2,1),col=c("black","red","blue"),cex=0.4)
}
```

Unfortunately, these permutation-based null estimations vary from  one permutation to another. Besides, this does not seem to fit the empirical distribution.
To obtain a stable estimate, one could try to concatenate all the measurements $Y^{(b)}$, for  $b=1,\dots,B$ and to use the resulting empirical distribution as  an estimation of the null distribution.

```{r concatenating permuted null}
  hist(Yheden,nclass=70,ylim=c(0,1.6/sqrt(2*pi)),freq=FALSE,main="") 
hist(Yperm,nclass=70,freq=FALSE,add=TRUE,col="lightblue")
  curve(dnorm(x),lwd=2,add=TRUE)
curve(dnorm(x,thetatilde,sigmatilde),lwd=2,lty=2,add=TRUE,col="red")
hist(Yheden,nclass=70,freq=FALSE,add=TRUE)
legend("topright",c("N(0,1)",
        paste("N(",signif(thetatilde,2),",",signif(sigmatilde^2,2),")"),"Permutation"),
       lwd=c(2,2,2),lty=c(1,2,1),col=c("black","red","lightblue"),cex=0.8)
```

Unfortunately, the corresponding estimator is close to  the theoretical null $\mathcal{N}(0,1)$ and not to the empirical distribution of the data. A possible explanation is that the structure of dependence of the variables is suppressed by the concatenation operation. 




# Confidence region with a stability indicator for empirical null procedures

In @RV2019, it has been shown that using the plug-in BH procedure is safe when the data are sufficiently sparse (only few true alternatives), but that no method can mimick the oracle plug-in BH procedure otherwise, in the minimax sense. This means that, without enough sparsity, there exists a model configuration where the oracle plug-in BH procedure is out of reach. An example of such a configuration is given in the proof of the lower bound in  @RV2019.  In this configuration, the numerical experiments in @RV2019 shows that classical procedure indeed fails: either the power is low, or the FDR control is lost (as it is the case for the `locfdr` package). 

However, this minimax result is pessimistic as, for some other distributions of the alternatives, plug-in could still be possible. This raises the challenge of assessing the performance of plug-in for the data at hand.

Given these facts, how could the user validate the conclusion of her empirical null procedure?



Keeping the assumption that the null distribution is Gaussian $\mathcal{N}(\theta,\sigma^2)$, we advise to draw a confidence map for $\theta$ and $\sigma$ as described above and as given in Section 6 of [@RV2019]. For this, we report all the parameters $(\theta,\sigma^2)$ such that $F_0=\mathcal{N}(\theta,\sigma^2)$ is inside the confidence region with coverage, say, $90\%$. To get more insight, we can display at each point $(\theta,\sigma^2)$ of the region, the number of rejections of the corresponding plug-in BH procedure.


```{r computing parameter confidence region }
getBHrejectionsCR=function(Y,alpha,pibar,thetarange,sigmarange){
  N=length(thetarange)
Admis=matrix(0,N,N)
for (i in 1:N){
  for (j in 1:N){
    Admis[i,j]=NA
    F0=function(x) pnorm((x-thetarange[i])/sigmarange[j])
    if(acceptF0(alpha,F0,pibar,Y)){
      Admis[i,j]= BH((Y-thetarange[i])/sigmarange[j],alpha=0.1)
    }
  }
}
return(Admis)
}
```

On the four above data sets, this parameter confidence region can be displayed as follows:

```{r displaying parameter confidence region}
plotconfidenceregion=function(Y){
  thetatilde=getthetatilde(Y)
  sigmatilde=getsigmatilde(Y)
  N=13
  thetarange=seq(thetatilde-0.6,thetatilde+0.6,length.out=N)
  sigmarange=seq(sigmatilde-0.6,sigmatilde+0.6,length.out=N)
  Admis=getBHrejectionsCR(Y,alpha=0.1,pibar=0.1,thetarange,sigmarange)
  par(mar=c(0.1, 2.1, 2.1, 4.5))
  plot(Admis[N:1,],xlab="",ylab="",digit=0,
  col=topo.colors,na.cell=FALSE,
  axis.row=axis(side=3,labels=signif(sigmarange,2),at=1:N),
  axis.col=axis(side=2,labels=signif(thetarange,2),at=1:N),line=1,main="")
}

#par(mfrow=c(2,2))
plotconfidenceregion(Ygolub)
plotconfidenceregion(Yheden)
plotconfidenceregion(Ywout)
plotconfidenceregion(YBourgon)

```

In each picture, the confidence region in the scaling $(\theta,\sigma)$ corresponds to the colored pixels. In each of these pixels, the displayed number is the rejection number of the plug-in BH procedure at level $\alpha=0.1$ using the corresponding scaling.

By definition, the oracle BH procedure belongs to this parameter confidence region with probability at least $90\%$. Hence, the minimum rejection number of plug-in BH in the confidence region is a lower bound on the best plug-in BH procedure rejection number. 
If this number is zero or very low, the user should certainly be cautious and declare no variables as significant. If this number is large enough, then the oracle BH procedure promises to find some signal in the data, and thus, the user might apply the plug-in BH procedure (or any other null-Gaussian-based estimation technics, like `locfdr` type algorithm) with more confidence. Alternatively, an extra care could be to declare as significant the variables rejected by *all* the plug-in BH procedures of the region, that is, by considering rejection sets rather than rejection numbers.

Importantly, this method provides an insight different than the minimax approach. The obtained confidence region adapts to the shape of the overall empirical c.d.f. of the measurements. Hence, it is not based on a least favorable configuration (lower bound), but rather accounts for the particular compatibility of the data with respect to the family of Gaussian null distribution.

Following these recommandations on the data sets considered above, the user thus might be cautious for the data @Golub99 and @Hed2001 and might declare many findings for the data @van2003 and @BGH2010. These conclusions markedly differ from the ones of the theoretical BH procedure.

To conclude, we have shown in this vignette that the effect of estimating the null distribution can be substantial and lead to very different conclusions from an analysis using the theoretical null. 
Let us finally note that, in fact, the `null estimation effect` can be even stronger than the `test multiplicity effect` itself. For the data @Golub99, we have seen that the theoretical BH make $`r nbrejetgolub[1]`$ discoveries, which are probably all false discoveries according to the above confidence region. Let us now compute the rejection number of the thresholding procedure at level $\alpha=10\%$, that correctly rescales the data but does not perform any multiple testing correction.


```{r null estimation versus multiple testing correction }
nbrejetnocorrection=sum(2*(1-pnorm((Ygolub-getthetatilde(Ygolub))
                                   /getsigmatilde(Ygolub)))<=0.1)
tab <- data.frame("Method" = c("Empirical BH procedure","Theoretical BH procedure",
                               "Non corrected empirical procedure"), "Rejection number" = c(nbrejetgolub[2],nbrejetgolub[1],nbrejetnocorrection),check.names = FALSE, row.names = NULL)
knitr::kable(tab)
```

While the theoretical BH makes $`r nbrejetgolub[1]`$ (presumably false) discoveries, the non corrected procedure only makes $`r nbrejetnocorrection`$ (presumably false) rejections. From this perspective, if one aims at avoiding false discoveries, the issue of estimating the null can be even more crucial than the issue of taking into account the multiplicity of the tests.


# Session information

```{r session-info}
sessionInfo()
```

# Reproducibility

To re-build this vignette from its source, use: 

```{r reproducibility, eval = FALSE}
rmarkdown::render("vignette.Rmd", output_format = "pdf_document")
# To keep intermediate files, add option 'clean = FALSE'
rmarkdown::render("vignette.Rmd", output_format = "html_document")
```

# References


